{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cmudict', 'cmudict.zip', 'gazetteers', 'gazetteers.zip', 'genesis', 'genesis.zip', 'gutenberg', 'gutenberg.zip', 'inaugural', 'inaugural.zip', 'movie_reviews', 'movie_reviews.zip', 'names', 'names.zip', 'omw', 'omw.zip', 'shakespeare', 'shakespeare.zip', 'state_union', 'state_union.zip', 'stopwords', 'stopwords.zip', 'treebank', 'treebank.zip', 'twitter_samples', 'twitter_samples.zip', 'udhr', 'udhr.zip', 'udhr2', 'udhr2.zip', 'wordnet', 'wordnet.zip', 'wordnet_ic', 'wordnet_ic.zip', 'words', 'words.zip']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(nltk.data.find(\"corpora\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamlet = nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')\n",
    "hamlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ The Tragedie of Hamlet by William Shakespeare 1599 ] Actus Primus . Scoena Prima . Enter Barnardo and Francisco two Centinels . Barnardo . Who ' s there ? Fran . Nay answer me : Stand & vnfold your selfe Bar . Long liue the King Fran . Barnardo ? Bar . He Fran . You come most carefully vpon your houre Bar . ' Tis now strook twelue , get thee to bed Francisco Fran . For this releefe much thankes : ' Tis bitter cold , And I am sicke at heart Barn . Haue you had quiet Guard ? Fran . Not a Mouse stirring Barn . Well , goodnight . If you do meet Horatio and Marcellus , the Riuals of my Watch , bid them make hast . Enter Horatio and Marcellus . Fran . I thinke I heare them . Stand : who ' s there ? Hor . Friends to this ground Mar . And Leige - men to the Dane Fran . Giue you good night Mar . O farwel honest Soldier , who hath relieu ' d you ? Fra . Barnardo ha ' s my place : giue you goodnight . Exit Fran . Mar . Holla Barnardo Bar . Say , what is Horatio there ? Hor . A peece of him Bar . Welcome Horatio , welcome good Marcellus Mar . What , ha ' s this thing appear ' d againe to night Bar . I haue seene nothing Mar . Horatio saies , ' tis but our Fantasie , And will not let beleefe take hold of him Touching this dreaded sight , twice seene of vs , Therefore I haue intreated him along With vs , to watch the minutes of this Night , That if againe this Apparition come , He may approue our eyes , and speake to it Hor . Tush , tush , ' twill not appeare Bar . Sit downe a - while , And let vs once againe assaile your eares , That are so fortified against our Story , What we two Nights haue seene Hor . Well , sit we downe , And let vs heare Barnardo speake of this Barn . Last night of all , When yond same Starre that ' s Westward from the Pole Had made his course t ' illume that part of Heauen Where now it burnes , Marcellus and my selfe , The Bell then beating one Mar . Peace , breake thee of : Enter the Ghost . Looke where it comes againe Barn . In the same figure , like the King that ' s dead Mar . Thou art a Scholler ; speake to it Horatio Barn . Lookes it not like the King ? Marke it Horatio Hora . Most like : It harrowes me with fear & wonder Barn . It would be spoke too Mar . Question it Horatio Hor . What art "
     ]
    }
   ],
   "source": [
    "for word in hamlet[:500]:\n",
    "    print(word, sep = ' ', end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech = \"\"\"The passing away of Bir Protik Taramon Bibi quietly in her home in Rajipur Upazila, at age 61, only 16 days before the commemoration of Victory Day, is truly a tragedy for us. For she was one of our few living heroes who could tell the tale of a freedom fighter, battling against a ferocious enemy, far less equipped in terms of arms, training or experience, far more passionate in the steadfast determination to free one's motherland from the clutches of oppression.\n",
    "\n",
    "We don't know whether she received the best medical treatment for her respiratory problems or diabetes. We do not know what hardship she suffered all those years after the war when she remained traceless until a determined researcher found her. It is tragic because there are so few women freedom fighters whom we know of and who have been able to share their stories, so few who have been recognised for their truly heroic deeds.\n",
    "\n",
    "And Taramon Bibi, a restless tomboy, managed to convince her mother to let her, a lanky young girl in her teens, to join the war for freedom. In an interview Taramon describes how she met Muhib Habildar, a freedom fighter, her mentor and godfather, who persuaded her to help his fellow Muktijodhhas in a camp in her village home Shankar Madhabpur Kurigram.\n",
    "\n",
    "Her initial job was to cook for the freedom fighters in the camp which she was happy to do but soon her comrades realised she was ready to take on far more serious tasks. Pretending to be a mentally challenged woman by smearing dirt on her hair, Taramon would go near the enemy camp to get information for her comrades. She would nimbly climb the betel nut trees and use her binoculars to spot the approaching enemy and alert her comrades. Impressed by her fearlessness, Muhib started to train her in how to use a rifle and stein gun—training that came to great use in various operations.\n",
    "\n",
    "The memory of the first time she went into direct combat was always very vivid for Taramon. During one of her vigils she spotted a gunboat carrying the Pak army heading towards where they were located. Taramon got prepared for combat with her comrades, and together, they succeeded in getting rid of the enemy. After that, Taramon had to fight with arms on many occasions and was often praised by the other Muktijoddhas for being a good marksman. In those days, she never thought about the risks involved in what she was doing. “We were fighting to free our country,” she said in an interview, “the last thing on my mind was worrying about my own safety.”\n",
    "\n",
    "She was totally committed to the cause of freeing her motherland just like so many other men and women at the time. Once when Taramon and her camp mates were hiding in the bunkers when the enemy changed their strategy and started an air-bombing onslaught. The Pak army raided the camp a few times and hurled bombs killing several people. But fortunately, Taramon escaped death. She had been in Sector 11 under the leadership of Sector Commander Abu Taher, Bir Uttam.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'passing',\n",
       " 'away',\n",
       " 'of',\n",
       " 'Bir',\n",
       " 'Protik',\n",
       " 'Taramon',\n",
       " 'Bibi',\n",
       " 'quietly',\n",
       " 'in',\n",
       " 'her',\n",
       " 'home',\n",
       " 'in',\n",
       " 'Rajipur',\n",
       " 'Upazila',\n",
       " ',',\n",
       " 'at',\n",
       " 'age',\n",
       " '61',\n",
       " ',',\n",
       " 'only',\n",
       " '16',\n",
       " 'days',\n",
       " 'before',\n",
       " 'the',\n",
       " 'commemoration',\n",
       " 'of',\n",
       " 'Victory',\n",
       " 'Day',\n",
       " ',',\n",
       " 'is',\n",
       " 'truly',\n",
       " 'a',\n",
       " 'tragedy',\n",
       " 'for',\n",
       " 'us',\n",
       " '.',\n",
       " 'For',\n",
       " 'she',\n",
       " 'was',\n",
       " 'one',\n",
       " 'of',\n",
       " 'our',\n",
       " 'few',\n",
       " 'living',\n",
       " 'heroes',\n",
       " 'who',\n",
       " 'could',\n",
       " 'tell',\n",
       " 'the',\n",
       " 'tale',\n",
       " 'of',\n",
       " 'a',\n",
       " 'freedom',\n",
       " 'fighter',\n",
       " ',',\n",
       " 'battling',\n",
       " 'against',\n",
       " 'a',\n",
       " 'ferocious',\n",
       " 'enemy',\n",
       " ',',\n",
       " 'far',\n",
       " 'less',\n",
       " 'equipped',\n",
       " 'in',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'arms',\n",
       " ',',\n",
       " 'training',\n",
       " 'or',\n",
       " 'experience',\n",
       " ',',\n",
       " 'far',\n",
       " 'more',\n",
       " 'passionate',\n",
       " 'in',\n",
       " 'the',\n",
       " 'steadfast',\n",
       " 'determination',\n",
       " 'to',\n",
       " 'free',\n",
       " 'one',\n",
       " \"'s\",\n",
       " 'motherland',\n",
       " 'from',\n",
       " 'the',\n",
       " 'clutches',\n",
       " 'of',\n",
       " 'oppression',\n",
       " '.',\n",
       " 'We',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'know',\n",
       " 'whether',\n",
       " 'she',\n",
       " 'received',\n",
       " 'the',\n",
       " 'best',\n",
       " 'medical',\n",
       " 'treatment',\n",
       " 'for',\n",
       " 'her',\n",
       " 'respiratory',\n",
       " 'problems',\n",
       " 'or',\n",
       " 'diabetes',\n",
       " '.',\n",
       " 'We',\n",
       " 'do',\n",
       " 'not',\n",
       " 'know',\n",
       " 'what',\n",
       " 'hardship',\n",
       " 'she',\n",
       " 'suffered',\n",
       " 'all',\n",
       " 'those',\n",
       " 'years',\n",
       " 'after',\n",
       " 'the',\n",
       " 'war',\n",
       " 'when',\n",
       " 'she',\n",
       " 'remained',\n",
       " 'traceless',\n",
       " 'until',\n",
       " 'a',\n",
       " 'determined',\n",
       " 'researcher',\n",
       " 'found',\n",
       " 'her',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'tragic',\n",
       " 'because',\n",
       " 'there',\n",
       " 'are',\n",
       " 'so',\n",
       " 'few',\n",
       " 'women',\n",
       " 'freedom',\n",
       " 'fighters',\n",
       " 'whom',\n",
       " 'we',\n",
       " 'know',\n",
       " 'of',\n",
       " 'and',\n",
       " 'who',\n",
       " 'have',\n",
       " 'been',\n",
       " 'able',\n",
       " 'to',\n",
       " 'share',\n",
       " 'their',\n",
       " 'stories',\n",
       " ',',\n",
       " 'so',\n",
       " 'few',\n",
       " 'who',\n",
       " 'have',\n",
       " 'been',\n",
       " 'recognised',\n",
       " 'for',\n",
       " 'their',\n",
       " 'truly',\n",
       " 'heroic',\n",
       " 'deeds',\n",
       " '.',\n",
       " 'And',\n",
       " 'Taramon',\n",
       " 'Bibi',\n",
       " ',',\n",
       " 'a',\n",
       " 'restless',\n",
       " 'tomboy',\n",
       " ',',\n",
       " 'managed',\n",
       " 'to',\n",
       " 'convince',\n",
       " 'her',\n",
       " 'mother',\n",
       " 'to',\n",
       " 'let',\n",
       " 'her',\n",
       " ',',\n",
       " 'a',\n",
       " 'lanky',\n",
       " 'young',\n",
       " 'girl',\n",
       " 'in',\n",
       " 'her',\n",
       " 'teens',\n",
       " ',',\n",
       " 'to',\n",
       " 'join',\n",
       " 'the',\n",
       " 'war',\n",
       " 'for',\n",
       " 'freedom',\n",
       " '.',\n",
       " 'In',\n",
       " 'an',\n",
       " 'interview',\n",
       " 'Taramon',\n",
       " 'describes',\n",
       " 'how',\n",
       " 'she',\n",
       " 'met',\n",
       " 'Muhib',\n",
       " 'Habildar',\n",
       " ',',\n",
       " 'a',\n",
       " 'freedom',\n",
       " 'fighter',\n",
       " ',',\n",
       " 'her',\n",
       " 'mentor',\n",
       " 'and',\n",
       " 'godfather',\n",
       " ',',\n",
       " 'who',\n",
       " 'persuaded',\n",
       " 'her',\n",
       " 'to',\n",
       " 'help',\n",
       " 'his',\n",
       " 'fellow',\n",
       " 'Muktijodhhas',\n",
       " 'in',\n",
       " 'a',\n",
       " 'camp',\n",
       " 'in',\n",
       " 'her',\n",
       " 'village',\n",
       " 'home',\n",
       " 'Shankar',\n",
       " 'Madhabpur',\n",
       " 'Kurigram',\n",
       " '.',\n",
       " 'Her',\n",
       " 'initial',\n",
       " 'job',\n",
       " 'was',\n",
       " 'to',\n",
       " 'cook',\n",
       " 'for',\n",
       " 'the',\n",
       " 'freedom',\n",
       " 'fighters',\n",
       " 'in',\n",
       " 'the',\n",
       " 'camp',\n",
       " 'which',\n",
       " 'she',\n",
       " 'was',\n",
       " 'happy',\n",
       " 'to',\n",
       " 'do',\n",
       " 'but',\n",
       " 'soon',\n",
       " 'her',\n",
       " 'comrades',\n",
       " 'realised',\n",
       " 'she',\n",
       " 'was',\n",
       " 'ready',\n",
       " 'to',\n",
       " 'take',\n",
       " 'on',\n",
       " 'far',\n",
       " 'more',\n",
       " 'serious',\n",
       " 'tasks',\n",
       " '.',\n",
       " 'Pretending',\n",
       " 'to',\n",
       " 'be',\n",
       " 'a',\n",
       " 'mentally',\n",
       " 'challenged',\n",
       " 'woman',\n",
       " 'by',\n",
       " 'smearing',\n",
       " 'dirt',\n",
       " 'on',\n",
       " 'her',\n",
       " 'hair',\n",
       " ',',\n",
       " 'Taramon',\n",
       " 'would',\n",
       " 'go',\n",
       " 'near',\n",
       " 'the',\n",
       " 'enemy',\n",
       " 'camp',\n",
       " 'to',\n",
       " 'get',\n",
       " 'information',\n",
       " 'for',\n",
       " 'her',\n",
       " 'comrades',\n",
       " '.',\n",
       " 'She',\n",
       " 'would',\n",
       " 'nimbly',\n",
       " 'climb',\n",
       " 'the',\n",
       " 'betel',\n",
       " 'nut',\n",
       " 'trees',\n",
       " 'and',\n",
       " 'use',\n",
       " 'her',\n",
       " 'binoculars',\n",
       " 'to',\n",
       " 'spot',\n",
       " 'the',\n",
       " 'approaching',\n",
       " 'enemy',\n",
       " 'and',\n",
       " 'alert',\n",
       " 'her',\n",
       " 'comrades',\n",
       " '.',\n",
       " 'Impressed',\n",
       " 'by',\n",
       " 'her',\n",
       " 'fearlessness',\n",
       " ',',\n",
       " 'Muhib',\n",
       " 'started',\n",
       " 'to',\n",
       " 'train',\n",
       " 'her',\n",
       " 'in',\n",
       " 'how',\n",
       " 'to',\n",
       " 'use',\n",
       " 'a',\n",
       " 'rifle',\n",
       " 'and',\n",
       " 'stein',\n",
       " 'gun—training',\n",
       " 'that',\n",
       " 'came',\n",
       " 'to',\n",
       " 'great',\n",
       " 'use',\n",
       " 'in',\n",
       " 'various',\n",
       " 'operations',\n",
       " '.',\n",
       " 'The',\n",
       " 'memory',\n",
       " 'of',\n",
       " 'the',\n",
       " 'first',\n",
       " 'time',\n",
       " 'she',\n",
       " 'went',\n",
       " 'into',\n",
       " 'direct',\n",
       " 'combat',\n",
       " 'was',\n",
       " 'always',\n",
       " 'very',\n",
       " 'vivid',\n",
       " 'for',\n",
       " 'Taramon',\n",
       " '.',\n",
       " 'During',\n",
       " 'one',\n",
       " 'of',\n",
       " 'her',\n",
       " 'vigils',\n",
       " 'she',\n",
       " 'spotted',\n",
       " 'a',\n",
       " 'gunboat',\n",
       " 'carrying',\n",
       " 'the',\n",
       " 'Pak',\n",
       " 'army',\n",
       " 'heading',\n",
       " 'towards',\n",
       " 'where',\n",
       " 'they',\n",
       " 'were',\n",
       " 'located',\n",
       " '.',\n",
       " 'Taramon',\n",
       " 'got',\n",
       " 'prepared',\n",
       " 'for',\n",
       " 'combat',\n",
       " 'with',\n",
       " 'her',\n",
       " 'comrades',\n",
       " ',',\n",
       " 'and',\n",
       " 'together',\n",
       " ',',\n",
       " 'they',\n",
       " 'succeeded',\n",
       " 'in',\n",
       " 'getting',\n",
       " 'rid',\n",
       " 'of',\n",
       " 'the',\n",
       " 'enemy',\n",
       " '.',\n",
       " 'After',\n",
       " 'that',\n",
       " ',',\n",
       " 'Taramon',\n",
       " 'had',\n",
       " 'to',\n",
       " 'fight',\n",
       " 'with',\n",
       " 'arms',\n",
       " 'on',\n",
       " 'many',\n",
       " 'occasions',\n",
       " 'and',\n",
       " 'was',\n",
       " 'often',\n",
       " 'praised',\n",
       " 'by',\n",
       " 'the',\n",
       " 'other',\n",
       " 'Muktijoddhas',\n",
       " 'for',\n",
       " 'being',\n",
       " 'a',\n",
       " 'good',\n",
       " 'marksman',\n",
       " '.',\n",
       " 'In',\n",
       " 'those',\n",
       " 'days',\n",
       " ',',\n",
       " 'she',\n",
       " 'never',\n",
       " 'thought',\n",
       " 'about',\n",
       " 'the',\n",
       " 'risks',\n",
       " 'involved',\n",
       " 'in',\n",
       " 'what',\n",
       " 'she',\n",
       " 'was',\n",
       " 'doing',\n",
       " '.',\n",
       " '“',\n",
       " 'We',\n",
       " 'were',\n",
       " 'fighting',\n",
       " 'to',\n",
       " 'free',\n",
       " 'our',\n",
       " 'country',\n",
       " ',',\n",
       " '”',\n",
       " 'she',\n",
       " 'said',\n",
       " 'in',\n",
       " 'an',\n",
       " 'interview',\n",
       " ',',\n",
       " '“',\n",
       " 'the',\n",
       " 'last',\n",
       " 'thing',\n",
       " 'on',\n",
       " 'my',\n",
       " 'mind',\n",
       " 'was',\n",
       " 'worrying',\n",
       " 'about',\n",
       " 'my',\n",
       " 'own',\n",
       " 'safety.',\n",
       " '”',\n",
       " 'She',\n",
       " 'was',\n",
       " 'totally',\n",
       " 'committed',\n",
       " 'to',\n",
       " 'the',\n",
       " 'cause',\n",
       " 'of',\n",
       " 'freeing',\n",
       " 'her',\n",
       " 'motherland',\n",
       " 'just',\n",
       " 'like',\n",
       " 'so',\n",
       " 'many',\n",
       " 'other',\n",
       " 'men',\n",
       " 'and',\n",
       " 'women',\n",
       " 'at',\n",
       " 'the',\n",
       " 'time',\n",
       " '.',\n",
       " 'Once',\n",
       " 'when',\n",
       " 'Taramon',\n",
       " 'and',\n",
       " 'her',\n",
       " 'camp',\n",
       " 'mates',\n",
       " 'were',\n",
       " 'hiding',\n",
       " 'in',\n",
       " 'the',\n",
       " 'bunkers',\n",
       " 'when',\n",
       " 'the',\n",
       " 'enemy',\n",
       " 'changed',\n",
       " 'their',\n",
       " 'strategy',\n",
       " 'and',\n",
       " 'started',\n",
       " 'an',\n",
       " 'air-bombing',\n",
       " 'onslaught',\n",
       " '.',\n",
       " 'The',\n",
       " 'Pak',\n",
       " 'army',\n",
       " 'raided',\n",
       " 'the',\n",
       " 'camp',\n",
       " 'a',\n",
       " 'few',\n",
       " 'times',\n",
       " 'and',\n",
       " 'hurled',\n",
       " 'bombs',\n",
       " 'killing',\n",
       " 'several',\n",
       " 'people',\n",
       " '.',\n",
       " 'But',\n",
       " 'fortunately',\n",
       " ',',\n",
       " 'Taramon',\n",
       " 'escaped',\n",
       " 'death',\n",
       " '.',\n",
       " 'She',\n",
       " 'had',\n",
       " 'been',\n",
       " 'in',\n",
       " 'Sector',\n",
       " '11',\n",
       " 'under',\n",
       " 'the',\n",
       " 'leadership',\n",
       " 'of',\n",
       " 'Sector',\n",
       " 'Commander',\n",
       " 'Abu',\n",
       " 'Taher',\n",
       " ',',\n",
       " 'Bir',\n",
       " 'Uttam',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech_tokens = word_tokenize(speech)\n",
    "speech_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speech_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fDist = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 27, ',': 25, 'her': 21, '.': 21, 'to': 18, 'in': 17, 'she': 15, 'a': 13, 'of': 12, 'and': 12, ...})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in speech_tokens:\n",
    "    fDist[word.lower()] += 1\n",
    "    \n",
    "fDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 27),\n",
       " (',', 25),\n",
       " ('her', 21),\n",
       " ('.', 21),\n",
       " ('to', 18),\n",
       " ('in', 17),\n",
       " ('she', 15),\n",
       " ('a', 13),\n",
       " ('of', 12),\n",
       " ('and', 12)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fDist_top10 = fDist.most_common(10)\n",
    "fDist_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import blankline_tokenize\n",
    "speech_blank = blankline_tokenize(speech)\n",
    "len(speech_blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams, trigrams, ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yesterday',\n",
       " 'is',\n",
       " 'a',\n",
       " 'history',\n",
       " ',',\n",
       " 'tomorrow',\n",
       " 'is',\n",
       " 'a',\n",
       " 'mystery',\n",
       " ',',\n",
       " 'but',\n",
       " 'today',\n",
       " 'is',\n",
       " 'a',\n",
       " 'gift',\n",
       " ',',\n",
       " 'that',\n",
       " \"'s\",\n",
       " 'why',\n",
       " 'it',\n",
       " 'is',\n",
       " 'called',\n",
       " 'present']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"Yesterday is a history, tomorrow is a mystery, but today is a gift, that's why it is called present\"\n",
    "quotes_tokens = word_tokenize(string)\n",
    "quotes_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Yesterday', 'is'),\n",
       " ('is', 'a'),\n",
       " ('a', 'history'),\n",
       " ('history', ','),\n",
       " (',', 'tomorrow'),\n",
       " ('tomorrow', 'is'),\n",
       " ('is', 'a'),\n",
       " ('a', 'mystery'),\n",
       " ('mystery', ','),\n",
       " (',', 'but'),\n",
       " ('but', 'today'),\n",
       " ('today', 'is'),\n",
       " ('is', 'a'),\n",
       " ('a', 'gift'),\n",
       " ('gift', ','),\n",
       " (',', 'that'),\n",
       " ('that', \"'s\"),\n",
       " (\"'s\", 'why'),\n",
       " ('why', 'it'),\n",
       " ('it', 'is'),\n",
       " ('is', 'called'),\n",
       " ('called', 'present')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_bigrams = list(bigrams(quotes_tokens))\n",
    "quotes_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Yesterday', 'is', 'a'),\n",
       " ('is', 'a', 'history'),\n",
       " ('a', 'history', ','),\n",
       " ('history', ',', 'tomorrow'),\n",
       " (',', 'tomorrow', 'is'),\n",
       " ('tomorrow', 'is', 'a'),\n",
       " ('is', 'a', 'mystery'),\n",
       " ('a', 'mystery', ','),\n",
       " ('mystery', ',', 'but'),\n",
       " (',', 'but', 'today'),\n",
       " ('but', 'today', 'is'),\n",
       " ('today', 'is', 'a'),\n",
       " ('is', 'a', 'gift'),\n",
       " ('a', 'gift', ','),\n",
       " ('gift', ',', 'that'),\n",
       " (',', 'that', \"'s\"),\n",
       " ('that', \"'s\", 'why'),\n",
       " (\"'s\", 'why', 'it'),\n",
       " ('why', 'it', 'is'),\n",
       " ('it', 'is', 'called'),\n",
       " ('is', 'called', 'present')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_trigrams = list(trigrams(quotes_tokens))\n",
    "quotes_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Yesterday', 'is', 'a', 'history'),\n",
       " ('is', 'a', 'history', ','),\n",
       " ('a', 'history', ',', 'tomorrow'),\n",
       " ('history', ',', 'tomorrow', 'is'),\n",
       " (',', 'tomorrow', 'is', 'a'),\n",
       " ('tomorrow', 'is', 'a', 'mystery'),\n",
       " ('is', 'a', 'mystery', ','),\n",
       " ('a', 'mystery', ',', 'but'),\n",
       " ('mystery', ',', 'but', 'today'),\n",
       " (',', 'but', 'today', 'is'),\n",
       " ('but', 'today', 'is', 'a'),\n",
       " ('today', 'is', 'a', 'gift'),\n",
       " ('is', 'a', 'gift', ','),\n",
       " ('a', 'gift', ',', 'that'),\n",
       " ('gift', ',', 'that', \"'s\"),\n",
       " (',', 'that', \"'s\", 'why'),\n",
       " ('that', \"'s\", 'why', 'it'),\n",
       " (\"'s\", 'why', 'it', 'is'),\n",
       " ('why', 'it', 'is', 'called'),\n",
       " ('it', 'is', 'called', 'present')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_ngrams = list(ngrams(quotes_tokens, 4))\n",
    "quotes_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "pst = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strike'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem('strikes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give :  give\n",
      "giving :  give\n",
      "gives :  give\n",
      "given :  given\n",
      "gave :  gave\n"
     ]
    }
   ],
   "source": [
    "words_to_stem = ['give', 'giving', 'gives', 'given', 'gave']\n",
    "for word in words_to_stem:\n",
    "    print(word, \": \", pst.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give :  giv\n",
      "giving :  giv\n",
      "gives :  giv\n",
      "given :  giv\n",
      "gave :  gav\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "lst = LancasterStemmer()\n",
    "for word in words_to_stem:\n",
    "    print(word, \": \", lst.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "word_lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give :  give\n",
      "giving :  giving\n",
      "gives :  give\n",
      "given :  given\n",
      "gave :  gave\n"
     ]
    }
   ],
   "source": [
    "for word in words_to_stem:\n",
    "    print(word, \": \", word_lem.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "punctuation = re.compile(r'[-.?!,:;()|0-9]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_punctuation = []\n",
    "for words in speech_tokens:\n",
    "    word = punctuation.sub(\"\", words)\n",
    "    if len(word) > 0 :\n",
    "        post_punctuation.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'passing',\n",
       " 'away',\n",
       " 'of',\n",
       " 'Bir',\n",
       " 'Protik',\n",
       " 'Taramon',\n",
       " 'Bibi',\n",
       " 'quietly',\n",
       " 'in',\n",
       " 'her',\n",
       " 'home',\n",
       " 'in',\n",
       " 'Rajipur',\n",
       " 'Upazila',\n",
       " 'at',\n",
       " 'age',\n",
       " 'only',\n",
       " 'days',\n",
       " 'before',\n",
       " 'the',\n",
       " 'commemoration',\n",
       " 'of',\n",
       " 'Victory',\n",
       " 'Day',\n",
       " 'is',\n",
       " 'truly',\n",
       " 'a',\n",
       " 'tragedy',\n",
       " 'for',\n",
       " 'us',\n",
       " 'For',\n",
       " 'she',\n",
       " 'was',\n",
       " 'one',\n",
       " 'of',\n",
       " 'our',\n",
       " 'few',\n",
       " 'living',\n",
       " 'heroes',\n",
       " 'who',\n",
       " 'could',\n",
       " 'tell',\n",
       " 'the',\n",
       " 'tale',\n",
       " 'of',\n",
       " 'a',\n",
       " 'freedom',\n",
       " 'fighter',\n",
       " 'battling',\n",
       " 'against',\n",
       " 'a',\n",
       " 'ferocious',\n",
       " 'enemy',\n",
       " 'far',\n",
       " 'less',\n",
       " 'equipped',\n",
       " 'in',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'arms',\n",
       " 'training',\n",
       " 'or',\n",
       " 'experience',\n",
       " 'far',\n",
       " 'more',\n",
       " 'passionate',\n",
       " 'in',\n",
       " 'the',\n",
       " 'steadfast',\n",
       " 'determination',\n",
       " 'to',\n",
       " 'free',\n",
       " 'one',\n",
       " \"'s\",\n",
       " 'motherland',\n",
       " 'from',\n",
       " 'the',\n",
       " 'clutches',\n",
       " 'of',\n",
       " 'oppression',\n",
       " 'We',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'know',\n",
       " 'whether',\n",
       " 'she',\n",
       " 'received',\n",
       " 'the',\n",
       " 'best',\n",
       " 'medical',\n",
       " 'treatment',\n",
       " 'for',\n",
       " 'her',\n",
       " 'respiratory',\n",
       " 'problems',\n",
       " 'or',\n",
       " 'diabetes',\n",
       " 'We',\n",
       " 'do',\n",
       " 'not',\n",
       " 'know',\n",
       " 'what',\n",
       " 'hardship',\n",
       " 'she',\n",
       " 'suffered',\n",
       " 'all',\n",
       " 'those',\n",
       " 'years',\n",
       " 'after',\n",
       " 'the',\n",
       " 'war',\n",
       " 'when',\n",
       " 'she',\n",
       " 'remained',\n",
       " 'traceless',\n",
       " 'until',\n",
       " 'a',\n",
       " 'determined',\n",
       " 'researcher',\n",
       " 'found',\n",
       " 'her',\n",
       " 'It',\n",
       " 'is',\n",
       " 'tragic',\n",
       " 'because',\n",
       " 'there',\n",
       " 'are',\n",
       " 'so',\n",
       " 'few',\n",
       " 'women',\n",
       " 'freedom',\n",
       " 'fighters',\n",
       " 'whom',\n",
       " 'we',\n",
       " 'know',\n",
       " 'of',\n",
       " 'and',\n",
       " 'who',\n",
       " 'have',\n",
       " 'been',\n",
       " 'able',\n",
       " 'to',\n",
       " 'share',\n",
       " 'their',\n",
       " 'stories',\n",
       " 'so',\n",
       " 'few',\n",
       " 'who',\n",
       " 'have',\n",
       " 'been',\n",
       " 'recognised',\n",
       " 'for',\n",
       " 'their',\n",
       " 'truly',\n",
       " 'heroic',\n",
       " 'deeds',\n",
       " 'And',\n",
       " 'Taramon',\n",
       " 'Bibi',\n",
       " 'a',\n",
       " 'restless',\n",
       " 'tomboy',\n",
       " 'managed',\n",
       " 'to',\n",
       " 'convince',\n",
       " 'her',\n",
       " 'mother',\n",
       " 'to',\n",
       " 'let',\n",
       " 'her',\n",
       " 'a',\n",
       " 'lanky',\n",
       " 'young',\n",
       " 'girl',\n",
       " 'in',\n",
       " 'her',\n",
       " 'teens',\n",
       " 'to',\n",
       " 'join',\n",
       " 'the',\n",
       " 'war',\n",
       " 'for',\n",
       " 'freedom',\n",
       " 'In',\n",
       " 'an',\n",
       " 'interview',\n",
       " 'Taramon',\n",
       " 'describes',\n",
       " 'how',\n",
       " 'she',\n",
       " 'met',\n",
       " 'Muhib',\n",
       " 'Habildar',\n",
       " 'a',\n",
       " 'freedom',\n",
       " 'fighter',\n",
       " 'her',\n",
       " 'mentor',\n",
       " 'and',\n",
       " 'godfather',\n",
       " 'who',\n",
       " 'persuaded',\n",
       " 'her',\n",
       " 'to',\n",
       " 'help',\n",
       " 'his',\n",
       " 'fellow',\n",
       " 'Muktijodhhas',\n",
       " 'in',\n",
       " 'a',\n",
       " 'camp',\n",
       " 'in',\n",
       " 'her',\n",
       " 'village',\n",
       " 'home',\n",
       " 'Shankar',\n",
       " 'Madhabpur',\n",
       " 'Kurigram',\n",
       " 'Her',\n",
       " 'initial',\n",
       " 'job',\n",
       " 'was',\n",
       " 'to',\n",
       " 'cook',\n",
       " 'for',\n",
       " 'the',\n",
       " 'freedom',\n",
       " 'fighters',\n",
       " 'in',\n",
       " 'the',\n",
       " 'camp',\n",
       " 'which',\n",
       " 'she',\n",
       " 'was',\n",
       " 'happy',\n",
       " 'to',\n",
       " 'do',\n",
       " 'but',\n",
       " 'soon',\n",
       " 'her',\n",
       " 'comrades',\n",
       " 'realised',\n",
       " 'she',\n",
       " 'was',\n",
       " 'ready',\n",
       " 'to',\n",
       " 'take',\n",
       " 'on',\n",
       " 'far',\n",
       " 'more',\n",
       " 'serious',\n",
       " 'tasks',\n",
       " 'Pretending',\n",
       " 'to',\n",
       " 'be',\n",
       " 'a',\n",
       " 'mentally',\n",
       " 'challenged',\n",
       " 'woman',\n",
       " 'by',\n",
       " 'smearing',\n",
       " 'dirt',\n",
       " 'on',\n",
       " 'her',\n",
       " 'hair',\n",
       " 'Taramon',\n",
       " 'would',\n",
       " 'go',\n",
       " 'near',\n",
       " 'the',\n",
       " 'enemy',\n",
       " 'camp',\n",
       " 'to',\n",
       " 'get',\n",
       " 'information',\n",
       " 'for',\n",
       " 'her',\n",
       " 'comrades',\n",
       " 'She',\n",
       " 'would',\n",
       " 'nimbly',\n",
       " 'climb',\n",
       " 'the',\n",
       " 'betel',\n",
       " 'nut',\n",
       " 'trees',\n",
       " 'and',\n",
       " 'use',\n",
       " 'her',\n",
       " 'binoculars',\n",
       " 'to',\n",
       " 'spot',\n",
       " 'the',\n",
       " 'approaching',\n",
       " 'enemy',\n",
       " 'and',\n",
       " 'alert',\n",
       " 'her',\n",
       " 'comrades',\n",
       " 'Impressed',\n",
       " 'by',\n",
       " 'her',\n",
       " 'fearlessness',\n",
       " 'Muhib',\n",
       " 'started',\n",
       " 'to',\n",
       " 'train',\n",
       " 'her',\n",
       " 'in',\n",
       " 'how',\n",
       " 'to',\n",
       " 'use',\n",
       " 'a',\n",
       " 'rifle',\n",
       " 'and',\n",
       " 'stein',\n",
       " 'gun—training',\n",
       " 'that',\n",
       " 'came',\n",
       " 'to',\n",
       " 'great',\n",
       " 'use',\n",
       " 'in',\n",
       " 'various',\n",
       " 'operations',\n",
       " 'The',\n",
       " 'memory',\n",
       " 'of',\n",
       " 'the',\n",
       " 'first',\n",
       " 'time',\n",
       " 'she',\n",
       " 'went',\n",
       " 'into',\n",
       " 'direct',\n",
       " 'combat',\n",
       " 'was',\n",
       " 'always',\n",
       " 'very',\n",
       " 'vivid',\n",
       " 'for',\n",
       " 'Taramon',\n",
       " 'During',\n",
       " 'one',\n",
       " 'of',\n",
       " 'her',\n",
       " 'vigils',\n",
       " 'she',\n",
       " 'spotted',\n",
       " 'a',\n",
       " 'gunboat',\n",
       " 'carrying',\n",
       " 'the',\n",
       " 'Pak',\n",
       " 'army',\n",
       " 'heading',\n",
       " 'towards',\n",
       " 'where',\n",
       " 'they',\n",
       " 'were',\n",
       " 'located',\n",
       " 'Taramon',\n",
       " 'got',\n",
       " 'prepared',\n",
       " 'for',\n",
       " 'combat',\n",
       " 'with',\n",
       " 'her',\n",
       " 'comrades',\n",
       " 'and',\n",
       " 'together',\n",
       " 'they',\n",
       " 'succeeded',\n",
       " 'in',\n",
       " 'getting',\n",
       " 'rid',\n",
       " 'of',\n",
       " 'the',\n",
       " 'enemy',\n",
       " 'After',\n",
       " 'that',\n",
       " 'Taramon',\n",
       " 'had',\n",
       " 'to',\n",
       " 'fight',\n",
       " 'with',\n",
       " 'arms',\n",
       " 'on',\n",
       " 'many',\n",
       " 'occasions',\n",
       " 'and',\n",
       " 'was',\n",
       " 'often',\n",
       " 'praised',\n",
       " 'by',\n",
       " 'the',\n",
       " 'other',\n",
       " 'Muktijoddhas',\n",
       " 'for',\n",
       " 'being',\n",
       " 'a',\n",
       " 'good',\n",
       " 'marksman',\n",
       " 'In',\n",
       " 'those',\n",
       " 'days',\n",
       " 'she',\n",
       " 'never',\n",
       " 'thought',\n",
       " 'about',\n",
       " 'the',\n",
       " 'risks',\n",
       " 'involved',\n",
       " 'in',\n",
       " 'what',\n",
       " 'she',\n",
       " 'was',\n",
       " 'doing',\n",
       " '“',\n",
       " 'We',\n",
       " 'were',\n",
       " 'fighting',\n",
       " 'to',\n",
       " 'free',\n",
       " 'our',\n",
       " 'country',\n",
       " '”',\n",
       " 'she',\n",
       " 'said',\n",
       " 'in',\n",
       " 'an',\n",
       " 'interview',\n",
       " '“',\n",
       " 'the',\n",
       " 'last',\n",
       " 'thing',\n",
       " 'on',\n",
       " 'my',\n",
       " 'mind',\n",
       " 'was',\n",
       " 'worrying',\n",
       " 'about',\n",
       " 'my',\n",
       " 'own',\n",
       " 'safety',\n",
       " '”',\n",
       " 'She',\n",
       " 'was',\n",
       " 'totally',\n",
       " 'committed',\n",
       " 'to',\n",
       " 'the',\n",
       " 'cause',\n",
       " 'of',\n",
       " 'freeing',\n",
       " 'her',\n",
       " 'motherland',\n",
       " 'just',\n",
       " 'like',\n",
       " 'so',\n",
       " 'many',\n",
       " 'other',\n",
       " 'men',\n",
       " 'and',\n",
       " 'women',\n",
       " 'at',\n",
       " 'the',\n",
       " 'time',\n",
       " 'Once',\n",
       " 'when',\n",
       " 'Taramon',\n",
       " 'and',\n",
       " 'her',\n",
       " 'camp',\n",
       " 'mates',\n",
       " 'were',\n",
       " 'hiding',\n",
       " 'in',\n",
       " 'the',\n",
       " 'bunkers',\n",
       " 'when',\n",
       " 'the',\n",
       " 'enemy',\n",
       " 'changed',\n",
       " 'their',\n",
       " 'strategy',\n",
       " 'and',\n",
       " 'started',\n",
       " 'an',\n",
       " 'airbombing',\n",
       " 'onslaught',\n",
       " 'The',\n",
       " 'Pak',\n",
       " 'army',\n",
       " 'raided',\n",
       " 'the',\n",
       " 'camp',\n",
       " 'a',\n",
       " 'few',\n",
       " 'times',\n",
       " 'and',\n",
       " 'hurled',\n",
       " 'bombs',\n",
       " 'killing',\n",
       " 'several',\n",
       " 'people',\n",
       " 'But',\n",
       " 'fortunately',\n",
       " 'Taramon',\n",
       " 'escaped',\n",
       " 'death',\n",
       " 'She',\n",
       " 'had',\n",
       " 'been',\n",
       " 'in',\n",
       " 'Sector',\n",
       " 'under',\n",
       " 'the',\n",
       " 'leadership',\n",
       " 'of',\n",
       " 'Sector',\n",
       " 'Commander',\n",
       " 'Abu',\n",
       " 'Taher',\n",
       " 'Bir',\n",
       " 'Uttam']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "527"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"Shakib is a pro when it comes to performance\"\n",
    "sent_tokens = word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Shakib', 'NN')]\n",
      "[('is', 'VBZ')]\n",
      "[('a', 'DT')]\n",
      "[('pro', 'NNS')]\n",
      "[('when', 'WRB')]\n",
      "[('it', 'PRP')]\n",
      "[('comes', 'VBZ')]\n",
      "[('to', 'TO')]\n",
      "[('performance', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "for word in sent_tokens:\n",
    "    print(nltk.pos_tag([word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (GPE Shakib/NNP)\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  pro/JJ\n",
      "  when/WRB\n",
      "  it/PRP\n",
      "  comes/VBZ\n",
      "  to/TO\n",
      "  performance/NN)\n"
     ]
    }
   ],
   "source": [
    "sent_tags = nltk.pos_tag(sent_tokens)\n",
    "sent_NER = ne_chunk(sent_tags)\n",
    "print(sent_NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_np = r\"NP: {<DT>?<JJ>*<NN>}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_parser = nltk.RegexpParser(grammar_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration paramaters or set the PATH environment variable.\n===========================================================================",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    728\u001b[0m             \u001b[0m_canvas_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m             \u001b[0m_canvas_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroy_widget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m             subprocess.call([find_binary('gs', binary_names=['gswin32c.exe', 'gswin64c.exe'], env_vars=['PATH'], verbose=False)] +\n\u001b[0m\u001b[0;32m    731\u001b[0m                             \u001b[1;34m'-q -dEPSCrop -sDEVICE=png16m -r90 -dTextAlphaBits=4 -dGraphicsAlphaBits=4 -dSAFER -dBATCH -dNOPAUSE -sOutputFile={0:} {1:}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m                             .format(out_path, in_path).split())\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\__init__.py\u001b[0m in \u001b[0;36mfind_binary\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    602\u001b[0m                 binary_names=None, url=None, verbose=False):\n\u001b[0;32m    603\u001b[0m     return next(find_binary_iter(name, path_to_bin, env_vars, searchpath,\n\u001b[1;32m--> 604\u001b[1;33m                                  binary_names, url, verbose))\n\u001b[0m\u001b[0;32m    605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m def find_jar_iter(name_pattern, path_to_jar=None, env_vars=(),\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\__init__.py\u001b[0m in \u001b[0;36mfind_binary_iter\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    596\u001b[0m     \"\"\"\n\u001b[0;32m    597\u001b[0m     for file in  find_file_iter(path_to_bin or name, env_vars, searchpath, binary_names,\n\u001b[1;32m--> 598\u001b[1;33m                      url, verbose):\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\__init__.py\u001b[0m in \u001b[0;36mfind_file_iter\u001b[1;34m(filename, env_vars, searchpath, file_names, url, verbose, finding_dir)\u001b[0m\n\u001b[0;32m    567\u001b[0m                         (filename, url))\n\u001b[0;32m    568\u001b[0m         \u001b[0mdiv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'='\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m75\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n\\n%s\\n%s\\n%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration paramaters or set the PATH environment variable.\n==========================================================================="
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [('Shakib', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('pro', 'JJ'), ('when', 'WRB'), ('it', 'PRP'), ('comes', 'VBZ'), ('to', 'TO'), Tree('NP', [('performance', 'NN')])])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_result = chunk_parser.parse(sent_tags)\n",
    "chunk_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cmudict', 'cmudict.zip', 'gazetteers', 'gazetteers.zip', 'genesis', 'genesis.zip', 'gutenberg', 'gutenberg.zip', 'inaugural', 'inaugural.zip', 'movie_reviews', 'movie_reviews.zip', 'names', 'names.zip', 'omw', 'omw.zip', 'shakespeare', 'shakespeare.zip', 'state_union', 'state_union.zip', 'stopwords', 'stopwords.zip', 'treebank', 'treebank.zip', 'twitter_samples', 'twitter_samples.zip', 'udhr', 'udhr.zip', 'udhr2', 'udhr2.zip', 'wordnet', 'wordnet.zip', 'wordnet_ic', 'wordnet_ic.zip', 'words', 'words.zip']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(nltk.data.find(\"corpora\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "print(movie_reviews.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive:  1000\n",
      "Negatvie:  1000\n"
     ]
    }
   ],
   "source": [
    "pos_rev = movie_reviews.fileids('pos')\n",
    "neg_rev = movie_reviews.fileids('neg')\n",
    "print(\"Positive: \", len(pos_rev))\n",
    "print(\"Negatvie: \", len(neg_rev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['films', 'adapted', 'from', 'comic', 'books', 'have', ...]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev = movie_reviews.words('pos/cv000_29590.txt')\n",
    "rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rev in neg_rev:\n",
    "    rev_text_neg = rev = nltk.corpus.movie_reviews.words(rev)\n",
    "    review_one_string = \" \".join(rev_text_neg)\n",
    "    review_one_string = review_one_string.replace(' ,', ',')\n",
    "    review_one_string = review_one_string.replace(' .', '.')\n",
    "    review_one_string = review_one_string.replace(\"\\' \", \"'\")\n",
    "    review_one_string = review_one_string.replace(\" \\'\", \"'\")\n",
    "    rev_list.append(review_one_string) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rev in pos_rev:\n",
    "    rev_text_neg = rev = nltk.corpus.movie_reviews.words(rev)\n",
    "    review_one_string = \" \".join(rev_text_neg)\n",
    "    review_one_string = review_one_string.replace(' ,', ',')\n",
    "    review_one_string = review_one_string.replace(' .', '.')\n",
    "    review_one_string = review_one_string.replace(\"\\' \", \"'\")\n",
    "    review_one_string = review_one_string.replace(\" \\'\", \"'\")\n",
    "    rev_list.append(review_one_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_targets = np.zeros((1000,), dtype = np.int)\n",
    "pos_targets = np.ones((1000,), dtype = np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = []\n",
    "for neg_tar in neg_targets:\n",
    "    target_list.append(neg_tar)\n",
    "    \n",
    "for pos_tar in pos_targets:\n",
    "    target_list.append(pos_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.Series(target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(lowercase = True, stop_words = 'english', min_df = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_count_vect = count_vect.fit_transform(rev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 23784)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_count_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '007',\n",
       " '05',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '100m',\n",
       " '101',\n",
       " '102',\n",
       " '103',\n",
       " '105',\n",
       " '106',\n",
       " '107',\n",
       " '108',\n",
       " '10th',\n",
       " '11',\n",
       " '110',\n",
       " '113',\n",
       " '115',\n",
       " '11th',\n",
       " '12',\n",
       " '126',\n",
       " '129',\n",
       " '13',\n",
       " '130',\n",
       " '132',\n",
       " '137',\n",
       " '13th',\n",
       " '14',\n",
       " '14th',\n",
       " '15',\n",
       " '150',\n",
       " '1500s',\n",
       " '155',\n",
       " '15th',\n",
       " '16',\n",
       " '160',\n",
       " '1600',\n",
       " '161',\n",
       " '16mm',\n",
       " '16th',\n",
       " '16x9',\n",
       " '17',\n",
       " '175',\n",
       " '1773',\n",
       " '17th',\n",
       " '18',\n",
       " '180',\n",
       " '1800s',\n",
       " '1839',\n",
       " '1869',\n",
       " '1871',\n",
       " '1888',\n",
       " '18th',\n",
       " '19',\n",
       " '1900',\n",
       " '1912',\n",
       " '1914',\n",
       " '1919',\n",
       " '1925',\n",
       " '1928',\n",
       " '1930',\n",
       " '1930s',\n",
       " '1932',\n",
       " '1933',\n",
       " '1935',\n",
       " '1937',\n",
       " '1938',\n",
       " '1939',\n",
       " '1940',\n",
       " '1940s',\n",
       " '1941',\n",
       " '1943',\n",
       " '1944',\n",
       " '1945',\n",
       " '1947',\n",
       " '1948',\n",
       " '1949',\n",
       " '1950',\n",
       " '1950s',\n",
       " '1953',\n",
       " '1954',\n",
       " '1957',\n",
       " '1958',\n",
       " '1959',\n",
       " '1960',\n",
       " '1960s',\n",
       " '1961',\n",
       " '1962',\n",
       " '1963',\n",
       " '1964',\n",
       " '1965',\n",
       " '1966',\n",
       " '1967',\n",
       " '1968',\n",
       " '1969',\n",
       " '1970',\n",
       " '1970s',\n",
       " '1971',\n",
       " '1972',\n",
       " '1973',\n",
       " '1974',\n",
       " '1975',\n",
       " '1976',\n",
       " '1977',\n",
       " '1978',\n",
       " '1979',\n",
       " '1980',\n",
       " '1980s',\n",
       " '1981',\n",
       " '1982',\n",
       " '1983',\n",
       " '1984',\n",
       " '1985',\n",
       " '1986',\n",
       " '1987',\n",
       " '1988',\n",
       " '1989',\n",
       " '1990',\n",
       " '1990s',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1994',\n",
       " '1995',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '1998s',\n",
       " '1999',\n",
       " '19th',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2001',\n",
       " '2013',\n",
       " '2017',\n",
       " '2020',\n",
       " '2029',\n",
       " '2050',\n",
       " '2058',\n",
       " '20s',\n",
       " '20th',\n",
       " '21',\n",
       " '2176',\n",
       " '21st',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '2400',\n",
       " '24th',\n",
       " '25',\n",
       " '250',\n",
       " '25th',\n",
       " '26',\n",
       " '26th',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '2d',\n",
       " '2nd',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '30th',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '35',\n",
       " '35mm',\n",
       " '36',\n",
       " '360',\n",
       " '37',\n",
       " '39',\n",
       " '3d',\n",
       " '3po',\n",
       " '3rd',\n",
       " '40',\n",
       " '400',\n",
       " '40s',\n",
       " '41',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '47',\n",
       " '48',\n",
       " '48th',\n",
       " '4th',\n",
       " '50',\n",
       " '500',\n",
       " '5000',\n",
       " '50s',\n",
       " '51',\n",
       " '52',\n",
       " '53',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '571',\n",
       " '58',\n",
       " '5th',\n",
       " '60',\n",
       " '600',\n",
       " '6000',\n",
       " '607',\n",
       " '60s',\n",
       " '61',\n",
       " '63',\n",
       " '64',\n",
       " '65',\n",
       " '66',\n",
       " '666',\n",
       " '69',\n",
       " '6th',\n",
       " '70',\n",
       " '700',\n",
       " '70mm',\n",
       " '70s',\n",
       " '73',\n",
       " '75',\n",
       " '76',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '7th',\n",
       " '80',\n",
       " '800',\n",
       " '80s',\n",
       " '81',\n",
       " '82',\n",
       " '83',\n",
       " '84',\n",
       " '85',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '89',\n",
       " '8mm',\n",
       " '8th',\n",
       " '90',\n",
       " '90210',\n",
       " '90s',\n",
       " '91',\n",
       " '911',\n",
       " '92',\n",
       " '93',\n",
       " '94',\n",
       " '95',\n",
       " '96',\n",
       " '97',\n",
       " '98',\n",
       " '99',\n",
       " '999',\n",
       " '9mm',\n",
       " '_____',\n",
       " '______',\n",
       " '_and_',\n",
       " '_babe_',\n",
       " '_blade',\n",
       " '_brazil_',\n",
       " '_do_',\n",
       " '_does_',\n",
       " '_don',\n",
       " '_film',\n",
       " '_in',\n",
       " '_is_',\n",
       " '_last_',\n",
       " '_life',\n",
       " '_must_',\n",
       " '_not_',\n",
       " '_real_',\n",
       " '_really_',\n",
       " '_saturday_night_live_',\n",
       " '_saving',\n",
       " '_scream_',\n",
       " '_that_',\n",
       " '_the',\n",
       " '_the_',\n",
       " 'aa',\n",
       " 'aaa',\n",
       " 'aaliyah',\n",
       " 'aardman',\n",
       " 'aaron',\n",
       " 'aback',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abandonment',\n",
       " 'abandons',\n",
       " 'abby',\n",
       " 'abc',\n",
       " 'abdomen',\n",
       " 'abducted',\n",
       " 'abduction',\n",
       " 'abductions',\n",
       " 'abe',\n",
       " 'abel',\n",
       " 'aberdeen',\n",
       " 'aberration',\n",
       " 'abetted',\n",
       " 'abetting',\n",
       " 'abhorrent',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abject',\n",
       " 'ablaze',\n",
       " 'able',\n",
       " 'ably',\n",
       " 'abo',\n",
       " 'aboard',\n",
       " 'abode',\n",
       " 'abolish',\n",
       " 'abolitionists',\n",
       " 'abominable',\n",
       " 'abomination',\n",
       " 'aborted',\n",
       " 'abortion',\n",
       " 'abortions',\n",
       " 'abound',\n",
       " 'abounding',\n",
       " 'abounds',\n",
       " 'abraham',\n",
       " 'abrahams',\n",
       " 'abrams',\n",
       " 'abrasive',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'abs',\n",
       " 'absence',\n",
       " 'absences',\n",
       " 'absent',\n",
       " 'absentee',\n",
       " 'absinthe',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolution',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'absorbing',\n",
       " 'absorbs',\n",
       " 'absorption',\n",
       " 'abstinence',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'absurdist',\n",
       " 'absurdities',\n",
       " 'absurdity',\n",
       " 'absurdly',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abundantly',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuser',\n",
       " 'abusers',\n",
       " 'abuses',\n",
       " 'abusing',\n",
       " 'abusive',\n",
       " 'abuzz',\n",
       " 'abysmal',\n",
       " 'abysmally',\n",
       " 'abyss',\n",
       " 'academia',\n",
       " 'academic',\n",
       " 'academy',\n",
       " 'accent',\n",
       " 'accented',\n",
       " 'accents',\n",
       " 'accentuate',\n",
       " 'accentuates',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accidently',\n",
       " 'accidents',\n",
       " 'acclaim',\n",
       " 'acclaimed',\n",
       " 'accolades',\n",
       " 'accommodates',\n",
       " 'accommodating',\n",
       " 'accompanied',\n",
       " 'accompanies',\n",
       " 'accompaniment',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplice',\n",
       " 'accomplices',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishes',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accordance',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'accordion',\n",
       " 'accosted',\n",
       " 'account',\n",
       " 'accountant',\n",
       " 'accounted',\n",
       " 'accounts',\n",
       " 'accumulated',\n",
       " 'accumulation',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusation',\n",
       " 'accusations',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accuses',\n",
       " 'accusing',\n",
       " 'accustomed',\n",
       " 'ace',\n",
       " 'acerbic',\n",
       " 'aces',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achiever',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'achilles',\n",
       " 'achingly',\n",
       " 'acid',\n",
       " 'acidic',\n",
       " 'ack',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledges',\n",
       " 'acknowledging',\n",
       " 'acknowledgment',\n",
       " 'acme',\n",
       " 'acquaintance',\n",
       " 'acquaintances',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquit',\n",
       " 'acquits',\n",
       " 'acquittal',\n",
       " 'acquitted',\n",
       " 'acres',\n",
       " 'acrimonious',\n",
       " 'acrobatic',\n",
       " 'acrobatics',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actioner',\n",
       " 'actioners',\n",
       " 'actionfest',\n",
       " 'actions',\n",
       " 'activated',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activist',\n",
       " 'activists',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'actresses',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actuality',\n",
       " 'actualization',\n",
       " 'actualizing',\n",
       " 'actually',\n",
       " 'acumen',\n",
       " 'acupuncture',\n",
       " 'acute',\n",
       " 'acutely',\n",
       " 'ad',\n",
       " 'ad2am',\n",
       " 'adage',\n",
       " 'adam',\n",
       " 'adams',\n",
       " 'adapt',\n",
       " 'adaptation',\n",
       " 'adaptations',\n",
       " 'adapted',\n",
       " 'adapting',\n",
       " 'adaption',\n",
       " 'add',\n",
       " 'addams',\n",
       " 'added',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addiction',\n",
       " 'addictive',\n",
       " 'addicts',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additions',\n",
       " 'addled',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'addy',\n",
       " 'ade',\n",
       " 'adefarasin',\n",
       " 'adept',\n",
       " 'adeptly',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adhere',\n",
       " 'adherence',\n",
       " 'adheres',\n",
       " 'adjacent',\n",
       " 'adjani',\n",
       " 'adjective',\n",
       " 'adjectives',\n",
       " 'adjoining',\n",
       " 'adjust',\n",
       " 'adjuster',\n",
       " 'adjusting',\n",
       " 'administration',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admired',\n",
       " 'admirer',\n",
       " 'admirers',\n",
       " 'admires',\n",
       " 'admiring',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admittance',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'admittingly',\n",
       " 'admonition',\n",
       " 'ado',\n",
       " 'adolescence',\n",
       " 'adolescent',\n",
       " 'adolescents',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adopting',\n",
       " 'adoption',\n",
       " 'adoptive',\n",
       " 'adopts',\n",
       " 'adorable',\n",
       " 'adoration',\n",
       " 'adore',\n",
       " 'adored',\n",
       " 'adores',\n",
       " 'adorned',\n",
       " 'adrenalin',\n",
       " 'adrenaline',\n",
       " 'adrian',\n",
       " 'adrien',\n",
       " 'adrift',\n",
       " 'adroitly',\n",
       " 'ads',\n",
       " 'adult',\n",
       " 'adulterous',\n",
       " 'adultery',\n",
       " 'adulthood',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancement',\n",
       " 'advances',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantages',\n",
       " 'advent',\n",
       " 'adventure',\n",
       " 'adventurer',\n",
       " 'adventures',\n",
       " 'adventurous',\n",
       " 'adversarial',\n",
       " 'adversary',\n",
       " 'adverse',\n",
       " 'adversity',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advertisements',\n",
       " 'advertiser',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advisable',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'adviser',\n",
       " 'advisers',\n",
       " 'advises',\n",
       " 'advising',\n",
       " 'advisor',\n",
       " 'advisors',\n",
       " 'advocate',\n",
       " 'advocating',\n",
       " 'aerial',\n",
       " 'aerosmith',\n",
       " 'aesthetic',\n",
       " 'aesthetically',\n",
       " 'aesthetics',\n",
       " 'afar',\n",
       " 'affability',\n",
       " 'affable',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'affect',\n",
       " 'affectations',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affectionately',\n",
       " 'affections',\n",
       " 'affects',\n",
       " 'affiliate',\n",
       " 'affiliated',\n",
       " 'affinity',\n",
       " 'affirmation',\n",
       " 'affirmative',\n",
       " 'affirming',\n",
       " 'affleck',\n",
       " 'afflicted',\n",
       " 'affliction',\n",
       " 'affluent',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afforded',\n",
       " 'affraid',\n",
       " 'affront',\n",
       " 'afi',\n",
       " 'aficionado',\n",
       " 'aficionados',\n",
       " 'afield',\n",
       " 'afloat',\n",
       " 'afo',\n",
       " 'afoot',\n",
       " 'afore',\n",
       " 'aforementioned',\n",
       " 'aformentioned',\n",
       " 'afoul',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'africans',\n",
       " 'afro',\n",
       " 'aftereffects',\n",
       " 'afterglow',\n",
       " 'afterlife',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'afternoons',\n",
       " 'aftertaste',\n",
       " 'afterthought',\n",
       " 'afterward',\n",
       " 'agape',\n",
       " 'agatha',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'ageing',\n",
       " 'agencies',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'aggravating',\n",
       " 'aggression',\n",
       " 'aggressive',\n",
       " 'aggressively',\n",
       " 'agile',\n",
       " 'agility',\n",
       " 'aging',\n",
       " 'agitated',\n",
       " 'ago',\n",
       " 'agonizing',\n",
       " 'agonizingly',\n",
       " 'agony',\n",
       " 'agree',\n",
       " 'agreeable',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreement',\n",
       " 'agrees',\n",
       " 'ah',\n",
       " 'ahabs',\n",
       " 'ahead',\n",
       " 'ahem',\n",
       " 'ahern',\n",
       " 'ahh',\n",
       " 'ahmed',\n",
       " 'aid',\n",
       " 'aidan',\n",
       " 'aide',\n",
       " 'aided',\n",
       " 'aiding',\n",
       " 'aids',\n",
       " 'aiello',\n",
       " 'ailing',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aimee',\n",
       " 'aiming',\n",
       " 'aimless',\n",
       " 'aimlessly',\n",
       " 'aims',\n",
       " 'ain',\n",
       " 'air',\n",
       " 'aircraft',\n",
       " 'aired',\n",
       " 'aires',\n",
       " 'airline',\n",
       " 'airliner',\n",
       " 'airlock',\n",
       " 'airplane',\n",
       " 'airplanes',\n",
       " 'airport',\n",
       " 'airwaves',\n",
       " 'airwolf',\n",
       " 'airy',\n",
       " 'aisle',\n",
       " 'aisles',\n",
       " 'aka',\n",
       " 'aki',\n",
       " 'akin',\n",
       " 'akira',\n",
       " 'akiva',\n",
       " 'akroyd',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'aladdin',\n",
       " 'alain',\n",
       " 'alan',\n",
       " 'alanis',\n",
       " 'alarm',\n",
       " 'alarmed',\n",
       " 'alarming',\n",
       " 'alas',\n",
       " 'alaska',\n",
       " 'albania',\n",
       " 'albanian',\n",
       " 'albeit',\n",
       " 'albert',\n",
       " 'alberta',\n",
       " 'albertson',\n",
       " 'albino',\n",
       " 'albinos',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'alcohol',\n",
       " 'alcoholic',\n",
       " 'alcoholics',\n",
       " 'alcoholism',\n",
       " 'alcott',\n",
       " 'alda',\n",
       " 'aldys',\n",
       " 'alec',\n",
       " 'alejandro',\n",
       " 'alek',\n",
       " 'alert',\n",
       " 'alerted',\n",
       " 'alessandro',\n",
       " 'alex',\n",
       " 'alexander',\n",
       " 'alexandra',\n",
       " 'alexandre',\n",
       " 'alfonso',\n",
       " 'alfre',\n",
       " 'alfred',\n",
       " 'algar',\n",
       " 'ali',\n",
       " 'alias',\n",
       " 'aliases',\n",
       " 'alice',\n",
       " 'alicia',\n",
       " 'alida',\n",
       " 'alien',\n",
       " 'alienate',\n",
       " 'alienated',\n",
       " 'alienates',\n",
       " 'alienating',\n",
       " 'alienation',\n",
       " 'aliens',\n",
       " 'align',\n",
       " 'alignment',\n",
       " 'alike',\n",
       " 'alison',\n",
       " 'alive',\n",
       " 'allah',\n",
       " 'allan',\n",
       " 'allegations',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'allegiance',\n",
       " 'allegiances',\n",
       " 'allegory',\n",
       " 'allegra',\n",
       " 'allen',\n",
       " 'allergy',\n",
       " 'alleviate',\n",
       " 'alley',\n",
       " 'alleys',\n",
       " 'alliance',\n",
       " 'alliances',\n",
       " 'allied',\n",
       " 'allies',\n",
       " 'alligator',\n",
       " 'alligators',\n",
       " 'allison',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'alluded',\n",
       " 'allure',\n",
       " 'alluring',\n",
       " 'allusion',\n",
       " 'allusions',\n",
       " 'ally',\n",
       " 'alma',\n",
       " 'almod',\n",
       " 'alongside',\n",
       " 'aloof',\n",
       " 'alot',\n",
       " 'aloud',\n",
       " 'alright',\n",
       " 'altar',\n",
       " 'alter',\n",
       " 'alteration',\n",
       " 'alterations',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'alternate',\n",
       " 'alternately',\n",
       " 'alternates',\n",
       " 'alternating',\n",
       " 'alternative',\n",
       " 'alternatively',\n",
       " 'alters',\n",
       " 'althea',\n",
       " 'altman',\n",
       " 'altogether',\n",
       " 'altough',\n",
       " 'alum',\n",
       " 'alumni',\n",
       " 'alumnus',\n",
       " 'alvarado',\n",
       " 'alvin',\n",
       " 'alyson',\n",
       " 'alyssa',\n",
       " 'alzheimer',\n",
       " 'amadeus',\n",
       " 'amalgamation',\n",
       " 'amanda',\n",
       " 'amarillo',\n",
       " 'amateur',\n",
       " 'amateurish',\n",
       " 'amateurishly',\n",
       " 'amaze',\n",
       " 'amazed',\n",
       " 'amazement',\n",
       " 'amazes',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazon',\n",
       " 'ambassador',\n",
       " 'ambassadors',\n",
       " 'amber',\n",
       " 'ambiance',\n",
       " 'ambience',\n",
       " 'ambient',\n",
       " 'ambiguities',\n",
       " 'ambiguity',\n",
       " 'ambiguous',\n",
       " 'ambiguously',\n",
       " 'ambition',\n",
       " 'ambitions',\n",
       " 'ambitious',\n",
       " 'ambitiously',\n",
       " 'ambivalence',\n",
       " 'ambivalent',\n",
       " 'ambrose',\n",
       " 'ambulance',\n",
       " 'ambush',\n",
       " 'amc',\n",
       " 'amen',\n",
       " 'amendment',\n",
       " 'amends',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americanized',\n",
       " 'americans',\n",
       " 'americas',\n",
       " 'ames',\n",
       " 'amiable',\n",
       " 'amicable',\n",
       " 'amid',\n",
       " 'amidala',\n",
       " 'amidst',\n",
       " 'amis',\n",
       " 'amish',\n",
       " 'amiss',\n",
       " 'amistad',\n",
       " 'ammo',\n",
       " 'ammunition',\n",
       " 'amnesia',\n",
       " 'amnesiac',\n",
       " 'amok',\n",
       " 'amon',\n",
       " 'amoral',\n",
       " 'amorality',\n",
       " 'amos',\n",
       " 'amounted',\n",
       " 'amounts',\n",
       " 'amphetamines',\n",
       " 'amphibian',\n",
       " 'ample',\n",
       " 'amplified',\n",
       " 'amply',\n",
       " 'amputated',\n",
       " 'amuck',\n",
       " 'amuse',\n",
       " 'amused',\n",
       " 'amusement',\n",
       " 'amusements',\n",
       " 'amusing',\n",
       " 'amusingly',\n",
       " 'amy',\n",
       " 'anaconda',\n",
       " 'anacondas',\n",
       " 'anakin',\n",
       " 'anal',\n",
       " 'analogy',\n",
       " 'analyses',\n",
       " 'analysis',\n",
       " 'analyst',\n",
       " 'analysts',\n",
       " 'analyze',\n",
       " 'analyzed',\n",
       " 'analyzing',\n",
       " 'anand',\n",
       " 'anarchic',\n",
       " 'anarchists',\n",
       " 'anarchy',\n",
       " 'anastasia',\n",
       " 'anatomy',\n",
       " 'ancestors',\n",
       " 'anchor',\n",
       " 'anchors',\n",
       " 'ancient',\n",
       " 'anders',\n",
       " 'anderson',\n",
       " 'andersons',\n",
       " 'andie',\n",
       " 'andre',\n",
       " 'andrea',\n",
       " 'andreas',\n",
       " 'andrew',\n",
       " 'andrews',\n",
       " 'android',\n",
       " 'androids',\n",
       " 'andromeda',\n",
       " 'andrzej',\n",
       " 'andy',\n",
       " 'anecdotal',\n",
       " 'anecdote',\n",
       " 'anecdotes',\n",
       " 'anemic',\n",
       " 'anew',\n",
       " 'ang',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angeles',\n",
       " 'angelic',\n",
       " 'angelina',\n",
       " 'angelo',\n",
       " 'angels',\n",
       " 'anger',\n",
       " ...]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_names = count_vect.get_feature_names()\n",
    "x_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_count_vect = pd.DataFrame(x_count_vect.toarray(), columns = x_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 23784)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_count_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>007</th>\n",
       "      <th>05</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>100m</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zoot</th>\n",
       "      <th>zorg</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zuko</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zwigoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  007  05  10  100  1000  100m  101  102   ...     zoom  zooming  \\\n",
       "0   0    0    0   0  10    0     0     0    0    0   ...        0        0   \n",
       "1   0    0    0   0   0    0     0     0    0    0   ...        0        0   \n",
       "2   0    0    0   0   0    0     0     0    0    0   ...        0        0   \n",
       "3   0    0    0   0   0    0     0     0    0    0   ...        0        0   \n",
       "4   0    0    0   0   0    0     0     0    0    0   ...        0        0   \n",
       "\n",
       "   zooms  zoot  zorg  zorro  zucker  zuko  zwick  zwigoff  \n",
       "0      0     0     0      0       0     0      0        0  \n",
       "1      0     0     0      0       0     0      0        0  \n",
       "2      0     0     0      0       0     0      0        0  \n",
       "3      0     0     0      0       0     0      0        0  \n",
       "4      0     0     0      0       0     0      0        0  \n",
       "\n",
       "[5 rows x 23784 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_count_vect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cv, x_test_cv, y_train_cv, y_test_cv = train_test_split(x_count_vect, y, test_size = 0.25, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 23784)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 23784)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred_gnb = gnb.fit(x_train_cv, y_train_cv).predict(x_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cv = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_cv.fit(x_train_cv, y_train_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cv = clf_cv.predict(x_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.798\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test_cv, y_pred_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[213,  45],\n",
       "       [ 56, 186]], dtype=int64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_clf_cv = confusion_matrix(y_test_cv, y_pred_cv)\n",
    "score_clf_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
